"""
ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬
"""
import sqlite3
import json
from datetime import datetime, timedelta
from config.settings import DB_PATH
from utils import logger
from typing import Optional, Dict, List, Any
from .classifier import classify_content

def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    logger.info("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹œì‘")

    # í´ë” ìƒì„±
    DB_PATH.parent.mkdir(parents=True, exist_ok=True)

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # í…Œì´ë¸” ìƒì„±
    cursor.executescript("""
        -- ë©”ì¸ í™œë™ í…Œì´ë¸”
        CREATE TABLE IF NOT EXISTS browsing_activity (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            
            -- URL ì •ë³´
            url TEXT NOT NULL UNIQUE,
            domain TEXT,
                                       
            -- content
            title TEXT,
            content TEXT,  -- ì „ì²´ ë³¸ë¬¸
            summary TEXT,  -- ìš”ì•½ë³¸
                         
            -- ë¶„ë¥˜
            category TEXT,  -- ì£¼ì œ (RAG, LangGraph, FastAPI...) 
            tags TEXT,     -- JSON ë°°ì—´
            source_type TEXT,  -- ì¶œì²˜ ìœ í˜• (blog, youtube, docs...) 
            
            -- ì¶”ê°€ ì •ë³´
            metadata TEXT      -- JSON, ì¶”ê°€ ì •ë³´    
        );
                         
        -- ì¸ë±ìŠ¤ ìƒì„± (ê²€ìƒ‰ì†ë„ í–¥ìƒ)
        CREATE INDEX IF NOT EXISTS idx_created_at
            ON browsing_activity(created_at);
                    
        CREATE INDEX IF NOT EXISTS idx_category
            ON browsing_activity(category);
                         
        CREATE INDEX IF NOT EXISTS idx_source_type
            ON browsing_activity(source_type);

        CREATE INDEX IF NOT EXISTS idx_domain
            ON browsing_activity(domain);            
                    
        -- ë¸Œë¦¬í•‘ íˆìŠ¤í† ë¦¬
        CREATE TABLE IF NOT EXISTS briefing_history (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            period_start DATE,      -- ì‹œì‘ ë‚ ì§œ
            period_end DATE,        -- ì¢…ë£Œ ë‚ ì§œ
            content TEXT,           -- Markdown í˜•ì‹
            activity_count INTEGER, -- í¬í•¨ëœ í™œë™ ìˆ˜
            metadata TEXT           -- JSON, í†µê³„ ë“±
        );
                         
        CREATE INDEX IF NOT EXISTS idx_briefing_created 
            ON briefing_history(created_at);
                    
        -- ì‚¬ìš©ì ì„¤ì • 
        CREATE TABLE IF NOT EXISTS user_settings (
            key TEXT PRIMARY KEY,
            value TEXT,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
    """)

    conn.commit()
    conn.close()

    logger.info(f"ë°ì´í„° ë² ì´ìŠ¤ ìƒì„± ì™„ë£Œ: {DB_PATH}")

def check_existing_activity(url: str) -> Optional[int]:
    """URLì´ DBì— ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ID ë°˜í™˜"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # ì¤‘ë³µ ì²´í¬
    cursor.execute(
        "SELECT id FROM browsing_activity WHERE url = ?",
        (url,)
    )
    existing = cursor.fetchone()
    conn.close()
    
    # ì¤‘ë³µ ì²˜ë¦¬
    if existing:
        return existing[0] # ê¸°ì¡´ Activity ID ë°˜í™˜
    
    return None

def save_activity(data: Dict[str, Any]) -> Optional[int]:
    """
    í™œë™ ì €ì¥
    
    Returns:
        int: activity_id (ìƒˆë¡œ ìƒì„± ë˜ëŠ” ê¸°ì¡´ ID)
        None: ì €ì¥ ì‹¤íŒ¨
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    tags_json = json.dumps(data.get('tags', []), ensure_ascii=False)
    metadata_json = json.dumps(data.get('metadata', {}), ensure_ascii=False)

    try:
        cursor.execute("""
            INSERT INTO browsing_activity 
               (url, domain, title, content, summary,
                category, tags, source_type, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            data['url'],
            data.get('domain'),
            data.get('title'),
            data.get('content'),
            data.get('summary'),
            data.get('category'),
            tags_json,
            data.get('source_type'),
            metadata_json
        ))

        conn.commit()
        activity_id = cursor.lastrowid

        logger.info(f"[OK] ì €ì¥ ì™„ë£Œ: ID {activity_id}")

        return activity_id
    
    except sqlite3.IntegrityError as e:
        logger.error(f"[FAIL] ë¬´ê²°ì„± ì—ëŸ¬: {e}")
        conn.rollback()
        return None
    
    except Exception as e:
        logger.error(f"[FAIL] ì €ì¥ ì‹¤íŒ¨: {e}")
        conn.rollback()
        return None
    
    finally:
        conn.close()

def get_activities(
        page: int =1,
        page_size: int = 10,
        category: Optional[str] = None,
        source_type: Optional[str] = None,
        start_date: Optional[str] = None,  
        end_date: Optional[str] = None,    
        tags: Optional[List[str]] = None
) -> List[Dict[str, Any]]:
    """
    í™œë™ ì¡°íšŒ (í•„í„°ë§ ì§€ì›)
    
    Args:
        page: ,
        page_size: ,
        category: ì¹´í…Œê³ ë¦¬ í•„í„°
        source_type: ì¶œì²˜ ìœ í˜• í•„í„°
        start_date: ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
        end_date : ì¢…ë£Œ ë‚ ì§œ 
        tags: íƒœê·¸ í•„í„° (ë¦¬ìŠ¤íŠ¸, OR ì¡°ê±´)
    
    Returns:
        {
            'total': int,
            'page': int,
            'page_size': int,
            'total_pages': int,
            'items': List[Dict]
        }
    """
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    query = "SELECT * FROM browsing_activity WHERE 1=1"
    params = []

    if category:
        query += " AND category = ?"
        params.append(category)

    if source_type:
        query += " AND source_type = ?"
        params.append(source_type)
    
    if start_date and end_date:
        # ë‘˜ ë‹¤ ìˆìœ¼ë©´: BETWEEN
        query += " AND DATE(created_at) BETWEEN ? AND ?"
        params.extend([start_date, end_date])
    elif start_date:
        # ì‹œì‘ì¼ë§Œ: ê·¸ë‚  ì´í›„
        query += " AND DATE(created_at) >= ?"
        params.extend(start_date)
    elif end_date:
        # ì¢…ë£Œì¼ë§Œ: ê·¸ ë‚  ì´ì „
        query += " AND DATE(created_at) <= ?"
        params.append(end_date)

    if tags and len(tags) > 0:
        tag_conditions = []
        for tag in tags:
            tag_clean = tag.lstrip('#')  # # ì œê±°
            tag_conditions.append("tags LIKE ?")
            params.append(f'%"{tag_clean}"%')

        query += " AND (" + " OR ".join(tag_conditions) + ")"

    # ì „ì²´ ê°œìˆ˜ ì¡°íšŒ
    count_query = query.replace("SELECT *", "SELECT COUNT(*)")
    cursor.execute(count_query, params)
    total = cursor.fetchone()[0]

    # í˜ì´ì§€ë„¤ì´ì…˜
    query += " ORDER BY created_at DESC LIMIT ? OFFSET ?"
    params.append(page_size)
    params.append((page - 1) * page_size)

    logger.debug(f"ì¿¼ë¦¬: {query}")
    logger.debug(f"íŒŒë¼ë¯¸í„°: {params}")
    
    # ë°ì´í„° ì¡°íšŒ
    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    # dict ë³€í™˜ + json íŒŒì‹± 
    activities = []
    for row in rows:
        activity = dict(row)
        activity['tags'] = json.loads(activity['tags']) if activity['tags'] else []
        activity['metadata'] = json.loads(activity['metadata']) if activity['metadata'] else {}
        activity['created_at'] = activity['created_at'][:10]
        activities.append(activity)

    logger.info(
        f"í™œë™ ì¡°íšŒ: {len(activities)}ê°œ "
        f"(í˜ì´ì§€: {page}/{(total + page_size - 1) // page_size}, "
        f"í•„í„°: ì¹´í…Œê³ ë¦¬={category}, ë‚ ì§œ={start_date}~{end_date}, íƒœê·¸={tags})"
    )

    return {
        "items": activities,
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size
    }

def save_briefing(
    period_start: str,
    period_end: str,
    content: str,
    activity_count: int,
    metadata: dict = None
) -> int:
    """ë¸Œë¦¬í•‘ ì €ì¥"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    metadata_json = json.dumps(metadata or {}, ensure_ascii=False)
    try:
        cursor.execute("""
            INSERT INTO briefing_history
            (period_start, period_end, content, activity_count, metadata)
            VALUES (?, ?, ?, ?, ?)
        """, (period_start, period_end, content, activity_count, metadata_json))
    except Exception as e:
        logger.error(f"ë¸Œë¦¬í•‘ ì €ì¥ ì‹¤íŒ¨: {e}")
    conn.commit()
    briefing_id = cursor.lastrowid
    conn.close()
    
    logger.info(f"ë¸Œë¦¬í•‘ ì €ì¥: (ID: {briefing_id})")
    return briefing_id

def get_briefings(limit: int = 10) -> List[Dict[str, Any]]:
    """ë¸Œë¦¬í•‘ ì¡°íšŒ"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute("""
        SELECT * 
        FROM briefing_history
        ORDER BY created_at DESC
        LIMIT ?
    """, (limit,))

    rows = cursor.fetchall()
    conn.close()

    briefings = []
    for row in rows:
        briefing = dict(row)
        briefing['metadata'] = json.loads(briefing['metadata']) if briefing['metadata'] else {}
        briefings.append(briefing)

    return briefings

def get_activities_for_briefing(days: int=7) -> List[Dict[str, Any]]:
    """
    ë¸Œë¦¬í•‘ ìƒì„±ì„ ìœ„í•´ ìµœê·¼ í™œë™ ë°ì´í„° ì¡°íšŒ
    """
    start_date = (datetime.now() - timedelta(days=days)).isoformat()

    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    # created_atì´ start_date ì´í›„ì¸ í™œë™ë§Œ ì¡°íšŒ
    cursor.execute("""
        SELECT *
        FROM browsing_activity
        WHERE created_at >= ?
        ORDER BY created_at DESC
    """, (start_date,))

    rows = cursor.fetchall()
    conn.close()

    activities = []
    for row in rows:
        activity = dict(row)
        # ì‹œê°„ ì •ë³´ë¥¼ ì œê±°í•˜ê³  ë‚ ì§œë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        activity['created_at'] = activity['created_at'].split(' ')[0] 
        activities.append(activity)

    return activities

def get_setting() -> list:
    """ì„¤ì • ì¡°íšŒ"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("SELECT value FROM user_settings WHERE key = 'user_topics'")
    row = cursor.fetchone()
    conn.close()
    
    if row:
        return json.loads(row[0])
    return []


def set_setting(topics: list):
    """ì„¤ì • ì €ì¥"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute("""
        INSERT OR REPLACE INTO user_settings (key, value, updated_at)
        VALUES ('user_topics', ?, CURRENT_TIMESTAMP)
    """, (json.dumps(topics)))
    
    conn.commit()
    conn.close()
    
    logger.debug(f"âš™ï¸ ì„¤ì • ì €ì¥: {topics}")

def search_by_keyword(keyword: str, limit: int = 10) -> List[Dict[str, Any]]:
    """í‚¤ì›Œë“œë¡œ í™œë™ ê²€ìƒ‰ (ì œëª©, ë³¸ë¬¸, íƒœê·¸, ì¹´í…Œê³ ë¦¬)"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    search_pattern = f"%{keyword}%"

    cursor.execute("""
        SELECT * FROM browsing_activity 
        WHERE title LIKE ?
            OR content LIKE ?
            OR tags LIKE ?
            OR category LIKE ?
        ORDER BY created_at DESC
        LIMIT ?
    """, (search_pattern, search_pattern, search_pattern, search_pattern, limit))

    rows = cursor.fetchall()
    conn.close()

    # dict ë³€í™˜
    activities = []
    for row in rows:
        activity = dict(row)
        activity['tags'] = json.loads(activity['tags']) if activity['tags'] else []
        activity['metadata'] = json.loads(activity['metadata']) if activity['metadata'] else {}
        activities.append(activity)
    
    logger.info(f"ê²€ìƒ‰ ì™„ë£Œ: '{keyword}' - {len(activities)}ê°œ ê²°ê³¼")
    return activities

def get_activity_by_id(activity_id: int) -> Optional[Dict[str, Any]]:
    """IDë¡œ í™œë™ ì¡°íšŒ"""
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("SELECT * FROM browsing_activity WHERE id = ?", (activity_id,))
    row = cursor.fetchone()
    conn.close()
    
    if row:
        activity = dict(row)
        activity['tags'] = json.loads(activity['tags']) if activity['tags'] else []
        activity['metadata'] = json.loads(activity['metadata']) if activity['metadata'] else {}
        return activity
    
    return None

def update_activity(activity_id: int, data: dict) -> bool:
    """í™œë™ ì—…ë°ì´íŠ¸"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    # ì—…ë°ì´íŠ¸í•  í•„ë“œë§Œ ì²˜ë¦¬
    updates = []
    values = []

    if 'title' in data:
        updates.append("title = ?")
        values.append(data['title'])
    
    if 'summary' in data:
        updates.append("summary = ?")
        values.append(data['summary'])
    
    if 'category' in data:
        updates.append("category = ?")
        values.append(data['category'])
    
    if 'tags' in data:
        updates.append("tags = ?")
        values.append(json.dumps(data['tags'], ensure_ascii=False))
    
    if 'source_type' in data:
        updates.append("source_type = ?")
        values.append(data['source_type'])
    
    if not updates:
        logger.warning("ì—…ë°ì´íŠ¸í•  í•„ë“œ ì—†ìŒ")
        conn.close()
        return False
    
    query = f"UPDATE browsing_activity SET {', '.join(updates)} WHERE id = ?"
    values.append(activity_id)

    try:
        cursor.execute(query, values)
        conn.commit()
        
        if cursor.rowcount > 0:
            logger.info(f"í™œë™ ì—…ë°ì´íŠ¸: ID {activity_id}")
            conn.close()
            updated = get_activity_by_id(activity_id)
            return updated
        else:
            logger.warning(f"í™œë™ ì—†ìŒ: ID {activity_id}")
            conn.close()
            return None
            
    except Exception as e:
        logger.error(f"ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        conn.close()
        return None
    

def delete_activity(activity_id: int) -> bool:
    """í™œë™ ì‚­ì œ"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute("DELETE FROM browsing_activity WHERE id = ?", (activity_id,))
        conn.commit()
        
        if cursor.rowcount > 0:
            logger.info(f"í™œë™ ì‚­ì œ: ID {activity_id}")
            conn.close()
            return True
        else:
            logger.warning(f"í™œë™ ì—†ìŒ: ID {activity_id}")
            conn.close()
            return False
            
    except Exception as e:
        logger.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
        conn.close()
        return False
    
def get_categories(date: Optional[str] = None) -> List[str]:
    """ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ
    
    Args:
        date: ë‚ ì§œ (Noneì´ë©´ ì „ì²´ ê¸°ê°„)
    
    Returns:
        List[str]: ì¹´í…Œê³ ë¦¬ ëª©ë¡
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    if date:
        # íŠ¹ì • ë‚ ì§œì˜ ì¹´í…Œê³ ë¦¬ë§Œ
        cursor.execute("""
            SELECT DISTINCT category, COUNT(*) as count
            FROM browsing_activity
            WHERE category IS NOT NULL
              AND DATE(created_at) = ?
            ORDER BY category
        """, (date,))

    else:
        cursor.execute("""
            SELECT DISTINCT category, COUNT(*) as count
            FROM browsing_activity
            WHERE category IS NOT NULL
            ORDER BY category
        """)

    rows = cursor.fetchall()
    conn.close()

    categories = [{"category": row[0], "count": row[1]} for row in rows]
    return categories

def get_tags(date: Optional[str] = None, category: Optional[str] = None, limit: int = 100) -> List[str]:
    """
    íƒœê·¸ ëª©ë¡ë§Œ ì¡°íšŒ (ìµœì í™”ë¨)
    - content, metadata ë“± ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œì™¸
    - tags ì»¬ëŸ¼ë§Œ SELECT

    Args:
        date: ë‚ ì§œ (Noneì´ë©´ ì „ì²´ ê¸°ê°„)
        category: ì¹´í…Œê³ ë¦¬ í•„í„° (Noneì´ë©´ ì „ì²´)
        limit: ê°œìˆ˜
    
    Returns:
        List[str]: íƒœê·¸ ëª©ë¡
    """
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    query = "SELECT tags FROM browsing_activity WHERE tags IS NOT NULL"
    params = []
    
    # ë‚ ì§œ í•„í„°
    if date:
        query += " AND DATE(created_at) = ?"
        params.append(date)
    
    # ì¹´í…Œê³ ë¦¬ í•„í„° ì¶”ê°€
    if category:
        query += " AND category = ?"
        params.append(category)
    
    # query += " ORDER BY created_at DESC LIMIT ?"
    # params.append(limit)

    cursor.execute(query, params)
    rows = cursor.fetchall()
    conn.close()

    all_tags = set()
    for row in rows:
        try:
            tags_list = json.loads(row[0])
            if isinstance(tags_list, list):
                all_tags.update(tags_list)
        except (json.JSONDecodeError, TypeError):
            continue
    tags = sorted(list(all_tags))
    logger.debug(
        f"íƒœê·¸ ì¡°íšŒ: {len(tags[:limit])}ê°œ "
        f"(ë‚ ì§œ={date or 'ì „ì²´'}, ì¹´í…Œê³ ë¦¬={category or 'ì „ì²´'})"
    )
    return tags[:limit]

def get_activity_metrics() -> Dict[str, Any]:
    """ì˜¤ëŠ˜ì˜ í™œë™ í†µê³„ (ì´ ê°œìˆ˜, ìµœë‹¤ ì¹´í…Œê³ ë¦¬, ì¹´í…Œê³ ë¦¬ ë¶„í¬) ì¡°íšŒ"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    today = datetime.now().date().isoformat()
    last_seven_days = (datetime.now() - timedelta(days=7)).isoformat()

    # ì˜¤ëŠ˜ ì´ í™œë™ìˆ˜
    cursor.execute("SELECT COUNT(id) FROM browsing_activity WHERE DATE(created_at) = ?", (today,))
    total_count_today = cursor.fetchone()[0]

    # ì˜¤ëŠ˜ ìµœë‹¤ ì¹´í…Œê³ ë¦¬
    cursor.execute("""
        SELECT category, COUNT(category) as count
        FROM browsing_activity
        WHERE DATE(created_at) = ? AND category IS NOT NULL
        GROUP BY category
        ORDER BY count DESC
    """, (today,))
    top_category_row = cursor.fetchone()
    top_category = top_category_row[0] if top_category_row else "N/A"

    # ì˜¤ëŠ˜ ìµœë‹¤ íƒœê·¸
    cursor.execute("""
        SELECT tags 
        FROM browsing_activity 
        WHERE created_at >= ? AND tags IS NOT NULL
    """, (today,))
    tags_today = cursor.fetchall()

    all_tags = []
    for row in tags_today:
        try:
            tags_list = json.loads(row[0])
            all_tags.extend(tags_list)
        except:
            pass

    from collections import Counter
    tag_counts = Counter(all_tags)
    top_tag = f"#{tag_counts.most_common(1)[0][0]}" if tag_counts else "N/A"

    # 4. ì¹´í…Œê³ ë¦¬ ë¶„í¬ (ìµœê·¼ 7ì¼ ê¸°ì¤€)
    cursor.execute("""
        SELECT category, COUNT(category) as count 
        FROM browsing_activity 
        WHERE created_at >= ? AND category IS NOT NULL
        GROUP BY category 
        ORDER BY count DESC
        LIMIT 5
    """, (last_seven_days,))
    
    category_rows = cursor.fetchall()
    total_activities_7d = sum([row[1] for row in category_rows])

    category_distribution = []
    for category, count in category_rows:
        percent = (count / total_activities_7d * 100) if total_activities_7d else 0
        category_distribution.append({
            "category": category,
            "count": count,
            "percent": round(percent)
        })

    conn.close()

    return {
        "total_count_today": total_count_today,
        "top_category": top_category,
        "top_tag": top_tag,
        "category_distribution": category_distribution
    }

def save_activity_with_ai(data: dict) -> int:
    """
    í™œë™ ì €ì¥ + AI ë¶„ë¥˜
    
    Args:
        data: {
            'url': str,
            'domain': str,
            'title': str,
            'content': str
        }
        
    Returns:
        activity_id
    """
    logger.info(f"í™œë™ ì €ì¥ (AI ë¶„ë¥˜ í¬í•¨): {data.get('title')}")

    # AI ë¶„ë¥˜
    if data.get('content'):
        logger.info("   ğŸ¤– AI ë¶„ë¥˜ ì¤‘...")
        ai_result = classify_content(
            data['title'],
            data['content']
        )
        
        # AI ê²°ê³¼ ì¶”ê°€
        data['category'] = ai_result['category']
        data['tags'] = ai_result['tags']
        data['summary'] = ai_result['summary']
        
        logger.info(f"ë¶„ë¥˜ ì™„ë£Œ: {ai_result['category']}")
    else:
        # AI ë¶„ë¥˜ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
        data['category'] = 'Uncategorized'
        data['tags'] = []
        data['summary'] = data.get('title', 'No summary')
    
    logger.info(f"save_activityì— ì¤„ data : {data}")
    
    return save_activity(data)

